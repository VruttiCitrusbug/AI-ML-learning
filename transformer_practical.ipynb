{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4a268b-421e-49fc-a1a8-bcf4c914f616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (4.40.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from transformers) (2024.5.10)\n",
      "Requirement already satisfied: requests in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\desktop\\ai-ml-learning\\venv\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1451cf-300e-48bc-ab3d-baf366ac896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline # pipeline is the collection of different model\n",
    "#When you give a transformer model the task of sentiment analysis,\n",
    "# it reads a piece of text, like a sentence or a paragraph,\n",
    "# and then it figures out if the overall emotion behind that text is positive, negative, or neutral.\n",
    "# It's like asking the model, \"How does this text make you feel?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbce3f97-ec1c-469f-9e13-1fff2db2f0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis = pipeline('sentiment-analysis')\n",
    "#trained model that classify the sentence is positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1890a6c2-b919-457b-862c-d6306eac0865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998841285705566}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis([\"it's very funny.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "486f6fe4-097e-4d04-852d-f980fe75b55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9974846839904785}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"not for that.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df8a011d-0b34-4d17-bb75-1b1ea94bc34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9991994500160217},\n",
       " {'label': 'POSITIVE', 'score': 0.9998570680618286},\n",
       " {'label': 'NEGATIVE', 'score': 0.7959883809089661}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"do not take it personal.\",\"fascinating fact\", \"i hope you don't hate it.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "120be2c6-a9a1-4029-8251-ca823f539cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe720b0-2662-4e58-b19c-73dbe897ec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'It\\'s very funny when you talk to this young girl who speaks a little bit more English, she says this but they don\\'t speak the same.\\n\\n\"I think I read somewhere that she was taken to by the authorities because I asked her'},\n",
       " {'generated_text': \"It's very funny when people make assumptions about the size or the size of a person, but in reality people tend to understand who a person is at face-value.\\n\\nIn order to understand the size of a person, you have to know\"},\n",
       " {'generated_text': \"It's very funny when you see someone who is talking about his own, his own life. It's like I'm kind of a victim. So you have to look at how good his life is. We do it a lot but it looks different\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It's very funny when\"\n",
    "generated_text = text_generator(prompt, max_length=50, num_return_sequences=3)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fedf213e-1a66-4d78-87c6-a375b137c9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "qa_model = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b33b5f10-dfaa-4dad-b5fa-00fcee512e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.3206569254398346,\n",
       " 'start': 21,\n",
       " 'end': 60,\n",
       " 'answer': 'the answer is same as 2 multiplied by 2'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_model(question=\"what is 2 plus 2\", context=\"when 2 is added by 2 the answer is same as 2 multiplied by 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f46a84a-872a-4cbe-961d-ce917f82138a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.31809642910957336, 'start': 69, 'end': 70, 'answer': '4'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_model(question=\"what is 2 plus 2\", context=\"when 2 is added by 2 the answer is same as 2 multiplied by 2 that is 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10019b0b-b104-4afa-95e3-bb3f378e75eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to FacebookAI/roberta-large-mnli and revision 130fb28 (https://huggingface.co/FacebookAI/roberta-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "zero_shot = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5395971-bf86-4c8e-8524-894042a377a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'It is what it is.',\n",
       " 'labels': ['negative', 'positive'],\n",
       " 'scores': [0.8014950156211853, 0.19850502908229828]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"It is what it is.\"\n",
    "candidate_labels = [\"positive\", \"negative\"]\n",
    "classifier(text, candidate_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
